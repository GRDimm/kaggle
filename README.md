# Kaggle Competitions

Welcome to my GitHub repository dedicated to my Kaggle competition entries. Here, you will find the projects I have worked on, the models I have used, and the scores achieved.

## Projects

| Project Name                 | Score Achieved   | Description                                                                 | Keywords | Homemade model |
|------------------------------|------------------|-----------------------------------------------------------------------------|---------------|-----------|
| 0 - Titanic - Machine Learning from Disaster | 0.78468 (Accuracy) | Predicting the survival of Titanic passengers using various classification models. | Random Forest, PCA, GridSearch | Y |
| 1 - House prices prediction | 0.13544 (RMSLE) | Predicting the price of houses using XGBoost and LightGBM. | XGBoost, RFE, Optuna, CV | Y |
| 2 - MNIST Digit recognition | 0.99360 (Accuracy) | Classification of pictures of numbers from 0 to 9 using a convolutional neural network. | CNN | N (implemented from paper) |
| 3 - Detect apocalyptic tweets | 0.82745 (Accuracy) | Classification of tweets using BERT. | NLP, BERT | Y |
| 4 - Earthquake prediction | 2.637s (MAE) | Predicting when the next earthquake will happpen. (This) | LightGBM | N (implemented from competition winners) |
